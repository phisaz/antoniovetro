
@inproceedings{beretta_invisible_2019,
	address = {Cham},
	title = {The {Invisible} {Power} of {Fairness}. {How} {Machine} {Learning} {Shapes} {Democracy}},
	isbn = {978-3-030-18305-9},
	abstract = {Many machine learning systems make extensive use of large amounts of data regarding human behaviors. Several researchers have found various discriminatory practices related to the use of human-related machine learning systems, for example in the field of criminal justice, credit scoring and advertising. Fair machine learning is therefore emerging as a new field of study to mitigate biases that are inadvertently incorporated into algorithms. Data scientists and computer engineers are making various efforts to provide definitions of fairness. In this paper, we provide an overview of the most widespread definitions of fairness in the field of machine learning, arguing that the ideas highlighting each formalization are closely related to different ideas of justice and to different interpretations of democracy embedded in our culture. This work intends to analyze the definitions of fairness that have been proposed to date to interpret the underlying criteria and to relate them to different ideas of democracy.},
	booktitle = {Advances in {Artificial} {Intelligence}},
	publisher = {Springer International Publishing},
	author = {Beretta, Elena and Santangelo, Antonio and Lepri, Bruno and Vetr√≤, Antonio and De Martin, Juan Carlos},
	editor = {Meurs, Marie-Jean and Rudzicz, Frank},
	year = {2019},
	pages = {238--250}
}